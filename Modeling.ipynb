{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a804a27f",
   "metadata": {},
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b10cc61",
   "metadata": {},
   "source": [
    "**As an initial trial, the model selected for this problem will be random forest algorithm. Tree based models proved to be a robust solution for tabular data.**\n",
    "\n",
    "\n",
    "\n",
    "**All the features present will be used for model training except for the name of the sender and reciever accounts which are nearly unique for each example**\n",
    "\n",
    "  \n",
    "**Two new features will be added which are:**\n",
    "\n",
    "**1- the difference between account balances before and after the transaction.**\n",
    "\n",
    "**2- binary feature which determines if all the balance in the origin account was transferred within the transaction or not.**\n",
    "       \n",
    "       \n",
    "**Data will be split so that 20% of the data used for validation keeping the ratio of minor class the same in both train and test sets.**\n",
    " \n",
    "\n",
    "**For better testing, macro precision, recal and f1-score will be used as metrics. The accuracy of minor class will be measured separately as well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c151d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##IMPORTING RELEVANT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39eda70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define global variables\n",
    "scaled_columns = [\"amount\", \"oldbalanceOrig\", \"newbalanceOrig\",\"oldbalanceDest\", \"newbalanceDest\"]\n",
    "\n",
    "final_cols_order = [\"amount\",\"oldbalanceOrig\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\", \n",
    "                    \"orig_diff\", \"dest_diff\", \"step\", \"type\", \"balance_equals_amount\", \"isFraud\"]\n",
    "\n",
    "transaction_type_dict = {\"PAYMENT\":0,\n",
    "                        \"TRANSFER\":1,\n",
    "                        \"CASH_OUT\":2,\n",
    "                        \"DEBIT\":3,\n",
    "                        \"CASH_IN\":4}\n",
    "\n",
    "inverse_label_dict = {0:\"Not_Fraud\",\n",
    "                      1:\"Fraud\"}\n",
    "\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb116f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading Data\n",
    "data = pd.read_csv(\"./Data/transactions_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3958922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##helper functions for feature engineering\n",
    "def get_balance_diff(old_balance, new_balance):\n",
    "    return new_balance-old_balance\n",
    "\n",
    "def balance_equals_amount(old_balance, amount):\n",
    "    return (old_balance==amount) *1\n",
    "    \n",
    "\n",
    "def add_features(df):\n",
    "    df_new = df.copy()\n",
    "    df_new[\"type\"] = df_new[\"type\"].map(lambda x:transaction_type_dict[x])\n",
    "    \n",
    "    scaler.fit(df_new[scaled_columns].values.reshape(-1, 1))\n",
    "    \n",
    "    for col in scaled_columns:\n",
    "        df_new[col] = scaler.transform(df_new[col].values.reshape(-1, 1));\n",
    "\n",
    "    df_new[\"orig_diff\"] = df_new.apply(lambda x: get_balance_diff(x.oldbalanceOrig,\n",
    "                                                                  x.newbalanceOrig), axis=1)\n",
    "    df_new[\"dest_diff\"] = df_new.apply(lambda x: get_balance_diff(x.oldbalanceDest,\n",
    "                                                                  x.newbalanceDest), axis=1)\n",
    "    df_new[\"balance_equals_amount\"] = df_new.apply(lambda x: balance_equals_amount(x.oldbalanceOrig,\n",
    "                                                                                   x.amount), axis=1)\n",
    "    \n",
    "    df_new.drop(['nameOrig', 'nameDest'], axis=1, inplace=True)\n",
    "    \n",
    "    df_new = df_new[final_cols_order]\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b79e863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrig</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>orig_diff</th>\n",
       "      <th>dest_diff</th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>balance_equals_amount</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.282944</td>\n",
       "      <td>-0.228273</td>\n",
       "      <td>-0.231629</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.003356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.285664</td>\n",
       "      <td>-0.279052</td>\n",
       "      <td>-0.279688</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.286238</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.279075</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.007224</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.282320</td>\n",
       "      <td>-0.272127</td>\n",
       "      <td>-0.276107</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351188</th>\n",
       "      <td>-0.230936</td>\n",
       "      <td>-0.230936</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351189</th>\n",
       "      <td>-0.230936</td>\n",
       "      <td>-0.230936</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.230936</td>\n",
       "      <td>-0.055363</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351190</th>\n",
       "      <td>0.656187</td>\n",
       "      <td>0.656187</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.942486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351191</th>\n",
       "      <td>0.656187</td>\n",
       "      <td>0.656187</td>\n",
       "      <td>-0.286300</td>\n",
       "      <td>-0.170504</td>\n",
       "      <td>0.771982</td>\n",
       "      <td>-0.942486</td>\n",
       "      <td>0.942486</td>\n",
       "      <td>699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351192</th>\n",
       "      <td>-0.286102</td>\n",
       "      <td>-0.282693</td>\n",
       "      <td>-0.282890</td>\n",
       "      <td>-0.242960</td>\n",
       "      <td>-0.242763</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6351193 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           amount  oldbalanceOrig  newbalanceOrig  oldbalanceDest  \\\n",
       "0       -0.282944       -0.228273       -0.231629       -0.286300   \n",
       "1       -0.285664       -0.279052       -0.279688       -0.286300   \n",
       "2       -0.286238       -0.286238       -0.286300       -0.286300   \n",
       "3       -0.286238       -0.286238       -0.286300       -0.279075   \n",
       "4       -0.282320       -0.272127       -0.276107       -0.286300   \n",
       "...           ...             ...             ...             ...   \n",
       "6351188 -0.230936       -0.230936       -0.286300       -0.286300   \n",
       "6351189 -0.230936       -0.230936       -0.286300       -0.286300   \n",
       "6351190  0.656187        0.656187       -0.286300       -0.286300   \n",
       "6351191  0.656187        0.656187       -0.286300       -0.170504   \n",
       "6351192 -0.286102       -0.282693       -0.282890       -0.242960   \n",
       "\n",
       "         newbalanceDest  orig_diff  dest_diff  step  type  \\\n",
       "0             -0.286300  -0.003356   0.000000     1     0   \n",
       "1             -0.286300  -0.000636   0.000000     1     0   \n",
       "2             -0.286300  -0.000062   0.000000     1     1   \n",
       "3             -0.286300  -0.000062  -0.007224     1     2   \n",
       "4             -0.286300  -0.003980   0.000000     1     0   \n",
       "...                 ...        ...        ...   ...   ...   \n",
       "6351188       -0.286300  -0.055363   0.000000   699     1   \n",
       "6351189       -0.230936  -0.055363   0.055363   699     2   \n",
       "6351190       -0.286300  -0.942486   0.000000   699     1   \n",
       "6351191        0.771982  -0.942486   0.942486   699     2   \n",
       "6351192       -0.242763  -0.000197   0.000197   699     3   \n",
       "\n",
       "         balance_equals_amount  isFraud  \n",
       "0                            0        0  \n",
       "1                            0        0  \n",
       "2                            1        1  \n",
       "3                            1        1  \n",
       "4                            0        0  \n",
       "...                        ...      ...  \n",
       "6351188                      1        1  \n",
       "6351189                      1        1  \n",
       "6351190                      1        1  \n",
       "6351191                      1        1  \n",
       "6351192                      0        0  \n",
       "\n",
       "[6351193 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add new features and display new dataframe\n",
    "data_new = add_features(data)\n",
    "display(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Splitting Data\n",
    "data, label = data_new.iloc[:,:-1], data_new.iloc[:,-1]\n",
    "\n",
    "X_train,X_cv,y_train,y_cv = train_test_split(data,label,test_size = 0.2, stratify = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca0a6b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Training Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators = 20)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d3edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Accuracy: 0.9999990159328347\n",
      "Minor Classes Training Accuracy: 0.9991901522513768\n"
     ]
    }
   ],
   "source": [
    "##Display Training Accuracy\n",
    "y_pred = clf.predict(X_train)\n",
    "print(f\"Total Training Accuracy: {accuracy_score(y_train,y_pred)}\")\n",
    "print(f\"Minor Classes Training Accuracy: {accuracy_score(y_train[y_train==1],y_pred[y_train==1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d0d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Validation Accuracy: 0.9999937019726209\n",
      "Minor Classes Validation Accuracy: 0.9948152948801037\n"
     ]
    }
   ],
   "source": [
    "##Display Validation Accuracy\n",
    "y_pred = clf.predict(X_cv)\n",
    "print(f\"Total Validation Accuracy: {accuracy_score(y_cv,y_pred)}\")\n",
    "print(f\"Minor Classes Validation Accuracy: {accuracy_score(y_cv[y_cv==1],y_pred[y_cv==1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b461a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Confusion Matrix\n",
    "array = confusion_matrix(y_cv,y_pred)\n",
    "df_cm = pd.DataFrame(array, index = [inverse_label_dict[i] for i in range(len(inverse_label_dict))],\n",
    "                  columns = [inverse_label_dict[i] for i in range(len(inverse_label_dict))])\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c3ec727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Fraud       1.00      1.00      1.00   1268696\n",
      "       Fraud       1.00      0.99      1.00      1543\n",
      "\n",
      "    accuracy                           1.00   1270239\n",
      "   macro avg       1.00      1.00      1.00   1270239\n",
      "weighted avg       1.00      1.00      1.00   1270239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Display the classification report\n",
    "print(classification_report(y_cv, y_pred, target_names=[\"Not Fraud\", \"Fraud\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2148fba",
   "metadata": {},
   "source": [
    "**Random forest performed perfectly on the dataset with almost 100% accuracy.**\n",
    "\n",
    "**Scaler and classifier will be saved as pickle files to be used in model deployment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2f34fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving scaler and classifier\n",
    "with open('scaler.pickle', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('classifier.pickle', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4d28f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
